[![CI](https://github.com/AparnaSarawadekar/high-performance-api-gateway/actions/workflows/ci.yml/badge.svg)](https://github.com/AparnaSarawadekar/high-performance-api-gateway/actions/workflows/ci.yml)

# High-Performance API Gateway for AI Workloads
*Go | Python | Node.js | Docker | Kubernetes | Azure*

> A distributed API gateway prototype optimized for **AI inference traffic** ‚Äî demonstrating scalable routing, caching, throttling, and observability patterns.

---

## Performance Targets

| Metric | Baseline Goal | Optimized Goal | Description |
|:--|:--:|:--:|:--|
| **Throughput** | 150 RPS | **200 RPS (+33%)** | Load-balanced routing + caching |
| **Latency (p95)** | ‚â§ 200 ms | **‚â§ 140 ms** | Lower tail latency under burst load |
| **Error Rate (5xx)** | < 0.1 % | ‚Äî | Consistent uptime under stress |
| **Cache Hit Ratio** | ‚Äî | 60‚Äì80 % | For repeatable idempotent GETs |

---

## Architecture Overview

| Component | Language | Purpose |
|:--|:--|:--|
| **api-gateway-go** | Go 1.25 | Entry point; routes & proxies traffic |
| **service-python** | FastAPI 3.12 | Simulated AI inference backend |
| **service-node** | Express 20.x | Fallback inference/test backend |

---

## Local Development with Docker Compose

### Prerequisites
- Docker Desktop (or Docker Engine + Compose v2)
- Make (optional but recommended)

### Quick Start
```bash
# From repository root
docker compose up -d --build
docker compose ps
```

Check that all containers are **healthy**:
```bash
curl -s http://localhost:8080/healthz | jq .
```

Expected:
```json
{ "ok": true, "service": "api-gateway-go", "uptime_ms": 12345 }
```

---

## Gateway MVP ‚Äî Step 7 (Routing + Health Checks)

The **Go API Gateway** exposes health info and proxies inference requests to both backend services.

### Routes

| Route | Method | Description | Target |
|:--|:--:|:--|:--|
| `/healthz` | GET | Returns gateway uptime and backend status | ‚Äî |
| `/infer/python` | POST | Proxies JSON to `service-python /infer` | FastAPI backend |
| `/infer/node` | POST | Proxies JSON to `service-node /infer` | Node backend |

### Environment Variables

| Variable | Description | Default |
|:--|:--|:--|
| `PY_SERVICE_URL` | URL of Python backend | `http://service-python:8001` |
| `NODE_SERVICE_URL` | URL of Node backend | `http://service-node:8002` |
| `PORT` | Gateway listening port | `8080` |

### Run & Test
```bash
docker compose up -d --build
curl -fsS http://localhost:8080/healthz
curl -fsS -X POST http://localhost:8080/infer/python \
  -H "Content-Type: application/json" -d '{"prompt":"hello"}'
curl -fsS -X POST http://localhost:8080/infer/node \
  -H "Content-Type: application/json" -d '{"prompt":"hello"}'
docker compose down -v
```

---

## Continuous Integration ‚Äî Step 8

Automated testing & builds run via  
[`.github/workflows/ci.yml`](.github/workflows/ci.yml).

### Pipeline Stages

| Job | Language | Key Actions |
|:--|:--|:--|
| **Go (Gateway)** | Go 1.25 | `go vet`, `go build`, `go test` |
| **Python (Service)** | Python 3.12 | `pip install`, `ruff check`, `pytest` |
| **Node (Service)** | Node 20 | `npm ci`, `eslint .` |
| **Docker Builds** | Docker 25 + Buildx | Build images for all services |
| **Compose Smoke Test** | Docker Compose V2 | Bring up stack, check `/healthz`, POST to `/infer/python` and `/infer/node`, then teardown |

### Run the Same Checks Locally
```bash
# From repo root

# --- Lint & Unit Tests ---
( cd api-gateway-go && go vet ./... && go test -v ./... )
( cd service-python && ruff check . )      # pytest optional
( cd service-node && npm ci && npm run lint )

# --- Docker Compose Smoke ---
docker compose up -d --build
curl -fsS http://localhost:8080/healthz
curl -fsS -X POST http://localhost:8080/infer/python \
  -H "Content-Type: application/json" -d '{"prompt":"hello"}'
curl -fsS -X POST http://localhost:8080/infer/node \
  -H "Content-Type: application/json" -d '{"prompt":"hello"}'
docker compose down -v
```

### ‚úÖ CI Status Badge
[![CI](https://github.com/AparnaSarawadekar/high-performance-api-gateway/actions/workflows/ci.yml/badge.svg)](https://github.com/AparnaSarawadekar/high-performance-api-gateway/actions/workflows/ci.yml)

---

## Repository Structure
```
.
‚îú‚îÄ‚îÄ api-gateway-go/        # Go gateway
‚îÇ   ‚îú‚îÄ‚îÄ main.go
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ main_test.go
‚îÇ   ‚îî‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ service-python/        # FastAPI service
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ service-node/          # Express service
‚îÇ   ‚îú‚îÄ‚îÄ index.js
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ .eslintrc.json
‚îÇ   ‚îú‚îÄ‚îÄ package-lock.json
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ load/              # k6 scripts (baseline & perf)
‚îú‚îÄ‚îÄ docs/                  # Setup, containerization, metrics
‚îÇ   ‚îú‚îÄ‚îÄ Containerization.md
‚îÇ   ‚îú‚îÄ‚îÄ Local-Tooling-Status.md
‚îÇ   ‚îú‚îÄ‚îÄ Perf_Baseline.md
‚îÇ   ‚îî‚îÄ‚îÄ Scope-and-Metrics.md
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îî‚îÄ‚îÄ .github/workflows/ci.yml
```

---

## üßæ Progress Summary (Completed Steps 1 ‚Äì 8)

| Step | Description | Status |
|:--:|:--|:--:|
| 1 | Define scope & success metrics | ‚úÖ |
| 2 | Set up local tooling (Docker, Kind, k6) | ‚úÖ |
| 3 | Create GitHub repo + project board | ‚úÖ |
| 4 | Scaffold services (Go + Python + Node) | ‚úÖ |
| 5 | Add Dockerfiles for all services | ‚úÖ |
| 6 | Wire up docker-compose (local orchestration) | ‚úÖ |
| 7 | Implement gateway MVP (routing + health) | ‚úÖ |
| 8 | Add GitHub Actions CI (pipeline) | ‚úÖ |
| 9 | Baseline Load Test (k6) | ‚úÖ |

---

## ‚ö° Step 9 ‚Äî Baseline Load Test with k6

This step benchmarks the **current performance** of the gateway stack before adding caching, throttling, or Redis.  
We‚Äôll measure **RPS, p95/p99 latency, and error rates** to establish a baseline.

---

### üß™ Test Script

File: `tests/load/k6_baseline.js`

```js
import http from 'k6/http';
import { check, sleep } from 'k6';

const BASE = __ENV.BASE_URL || 'http://localhost:8080';
const PAYLOAD = JSON.stringify({ prompt: 'hello world' });
const HEADERS = { 'Content-Type': 'application/json' };

export const options = {
  scenarios: {
    warmup: {
      executor: 'constant-arrival-rate',
      rate: 50,               
      timeUnit: '1s',
      duration: '30s',
      preAllocatedVUs: 50,
      maxVUs: 100,
      startTime: '0s',
    },
    baseline: {
      executor: 'constant-arrival-rate',
      rate: 150,              
      timeUnit: '1s',
      duration: '2m',
      preAllocatedVUs: 200,
      maxVUs: 300,
      startTime: '30s',
    },
  },
  thresholds: {
    http_req_failed: ['rate<0.001'],      
    http_req_duration: ['p(95)<200', 'p(99)<400'],
  },
  tags: { test_stage: 'baseline' },
};

export default function () {
  const res = http.post(`${BASE}/infer/python`, PAYLOAD, { headers: HEADERS });
  check(res, { 'status 200': (r) => r.status === 200 });
  sleep(0.05);
}
```

---

### ‚ñ∂Ô∏è Run the Baseline Test

From the repo root:

```bash
# 1Ô∏è‚É£ Ensure stack is up
docker compose up -d --build
curl -s http://localhost:8080/healthz

# 2Ô∏è‚É£ Run k6 test
k6 run --summary-export=tests/load/baseline_summary.json tests/load/k6_baseline.js
```

You‚Äôll see live results in the terminal, and a JSON summary will be saved to  
`tests/load/baseline_summary.json`.

---

### üìä Generate Markdown Summary

File: `tools/k6_summary_to_md.py`

```python
import json, datetime, pathlib

src = pathlib.Path("tests/load/baseline_summary.json")
dst = pathlib.Path("docs/Perf_Baseline.md")

data = json.loads(src.read_text())
m = data.get("metrics", {})
def get(mkey, vkey): return m.get(mkey, {}).get("values", {}).get(vkey, 0)

rps = get("http_reqs","rate")
p95 = get("http_req_duration","p(95)")
errors = get("http_req_failed","rate") * 100
count = get("http_reqs","count")

md = f"""# Baseline Performance (k6)

**Date:** {datetime.datetime.now():%Y-%m-%d %H:%M}  
**Script:** `tests/load/k6_baseline.js`

| Metric | Value |
|--|--:|
| Requests | {int(count):,} |
| Throughput (RPS) | {rps:.1f} |
| p95 Latency (ms) | {p95:.1f} |
| Error Rate (%) | {errors:.3f}% |

Targets:
- Throughput ‚â•150 RPS
- p95 ‚â§ 200 ms
- Error < 0.1 %

> This report was generated automatically from the k6 JSON summary.
"""

dst.write_text(md)
print(f"Wrote {dst}")
```

Run it:

```bash
python3 tools/k6_summary_to_md.py
```

A new file `docs/Perf_Baseline.md` will appear containing a Markdown report.

---

### Commit Artifacts

```bash
git add tests/load/k6_baseline.js tests/load/baseline_summary.json tools/k6_summary_to_md.py docs/Perf_Baseline.md
git commit -m "step9: add k6 baseline test + summary report"
git push origin main
```

---

### Expected Outcome

After Step 9, you‚Äôll have:
- A reproducible **load test** (`k6_baseline.js`)
- A **JSON metrics file**
- A readable **Markdown performance report**
- Documented baseline targets before optimization

### Step 9 Baseline Snapshot

| Metric | Value |
|:--|--:|
| RPS | ~1950 |
| p95 (ms) | ~1.92 |
| p99 (ms) | ~2.60 |
| Error Rate | 0.00% |

_Source: [`tests/load/baseline_console.txt`](tests/load/baseline_console.txt). Tag: `perf-baseline-v0`._

Next ‚Üí **Step 10 ‚Äî Add rate limiting & throttling in gateway (token bucket)**

---

## üë©‚Äçüíª Author
**Aparna Vivek Sarawadekar**  
*M.S. Computer Science @ UCR ‚Ä¢ Software Engineer (Cloud & AI Infrastructure)*  
[LinkedIn](https://linkedin.com/in/aparna-sarawadekar) | [GitHub](https://github.com/AparnaSarawadekar)
